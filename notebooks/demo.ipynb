{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2332a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_core.tools import tool\n",
    "from typing import TypedDict,Annotated\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "from langchain_core.messages import HumanMessage,BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage,AIMessage,SystemMessage,ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf7736f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ed62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "146286a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.config import get_stream_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cce21f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# web search tool \n",
    "from langchain_tavily import TavilySearch\n",
    "web_search_tool = TavilySearch(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9628b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File management tool\n",
    "from langchain_community.agent_toolkits import FileManagementToolkit\n",
    "\n",
    "working_directory = './'\n",
    "\n",
    "file_management_tools =FileManagementToolkit(\n",
    "    root_dir=str(working_directory),\n",
    "    selected_tools=[\"read_file\", \"write_file\", \"list_directory\"]\n",
    ").get_tools()\n",
    "\n",
    "\n",
    "read_tool, write_tool, list_tool = file_management_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b431f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import BaseTool,tool\n",
    "from langgraph.prebuilt.interrupt import HumanInterruptConfig,HumanInterrupt\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.types import interrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05944243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_human_in_the_loop(toolhitl,interrupt_config: HumanInterruptConfig = None) -> BaseTool:\n",
    "    \"\"\"Wrap a tool to support human-in-the-loop review.\"\"\"\n",
    "\n",
    "    if not isinstance(toolhitl, BaseTool):\n",
    "        toolhitl = tool(toolhitl)\n",
    "\n",
    "    if interrupt_config is None:\n",
    "        interrupt_config = {\n",
    "            \"allow_accept\":True,\n",
    "            \"allow_edit\": True,\n",
    "            \"allow_respond\":True\n",
    "        }\n",
    "\n",
    "    @tool(toolhitl.name,description=toolhitl.description,args_schema=toolhitl.args_schema)\n",
    "    def call_tool_with_interrupt(config: RunnableConfig, **tool_input):\n",
    "        request: HumanInterrupt = {\n",
    "            'action_request':{\n",
    "                \"action\":toolhitl.name,\n",
    "                \"args\":tool_input\n",
    "            },\n",
    "            \"config\":interrupt_config,\n",
    "            \"description\": \"Please review the tool call\"\n",
    "        }\n",
    "\n",
    "        response = interrupt([request])[0]\n",
    "\n",
    "        # approve the tool call\n",
    "        if response[\"type\"] == \"accept\":\n",
    "            tool_response = toolhitl.invoke(tool_input, config)\n",
    "        # update tool call args\n",
    "        elif response[\"type\"] == \"edit\":\n",
    "            tool_input = response[\"args\"][\"args\"]\n",
    "            tool_response = toolhitl.invoke(tool_input, config)\n",
    "        # respond to the LLM with user feedback\n",
    "        elif response[\"type\"] == \"response\":\n",
    "            user_feedback = response[\"args\"]\n",
    "            tool_response = user_feedback\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported interrupt response type: {response['type']}\")\n",
    "\n",
    "        return tool_response\n",
    "    \n",
    "    return call_tool_with_interrupt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5d45ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arxiv\n",
    "import arxiv\n",
    "\n",
    "@tool(\"arxiv_search\")\n",
    "def arxiv_search(query: str,max_results: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Searches arXiv for papers matching the query.\n",
    "    - query: keywords, authors or title\n",
    "    - max_results: number of papers to return\n",
    "    \"\"\"\n",
    "    try:\n",
    "        writer = get_stream_writer()\n",
    "        writer(f\"Looking up research papers for topic : {query}\")\n",
    "        search = arxiv.Search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            sort_by=arxiv.SortCriterion.Relevance\n",
    "        )\n",
    "        papers = []\n",
    "        for result in search.results():\n",
    "            pdf_url = result.pdf_url if hasattr(result,\"pdf_url\") else result.entry_id.replace(\"abs\",\"pdf\")\n",
    "            papers.append(\n",
    "                f\"Title: {result.title}\\n\"\n",
    "                f\"Authors: {','.join(a.name for a in result.authors)}\\n\"\n",
    "                f'Published: {result.published.date()}\\n'\n",
    "                f\"Abstract: {result.summary.strip()}\\n\"\n",
    "                f\"Link: {result.entry_id}\\n\"\n",
    "                f\"PDF: {pdf_url}\\n\"\n",
    "                + \"-\"*80\n",
    "\n",
    "            )\n",
    "        if not papers:\n",
    "            return f\"No results found for '{query}\"\n",
    "        writer(f\"Acquired research papers for topic: {query}\")\n",
    "        return \"\\n\".join(papers)\n",
    "    except Exception as e:\n",
    "        return f\"Error during arXiv search: {e}\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee6a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_1712\\2627632007.py:1: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = arxiv_search(\"Quantum Machine Learning\")\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.smith.langchain.com:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /info HTTP/1.1\" 200 817\n",
      "DEBUG:langsmith.client:Tracing control thread func compress parallel called\n",
      "DEBUG:langsmith.client:Sending multipart request with context: trace=5808b751-27d2-461d-b163-adef7bcf6d50,id=5808b751-27d2-461d-b163-adef7bcf6d50; trace=ede264a0-e728-4cdc-b41a-005d345b552f,id=ede264a0-e728-4cdc-b41a-005d345b552f\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 34\n",
      "DEBUG:langsmith.client:Sending compressed multipart request with context: trace=ede264a0-e728-4cdc-b41a-005d345b552f,id=ede264a0-e728-4cdc-b41a-005d345b552f\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 34\n",
      "DEBUG:langsmith.client:Sending compressed multipart request with context: trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=2abb8cdf-515a-49da-94c6-da2572b892a5; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=b439446b-94ce-4d19-bff7-2da4bc63245c; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=cbf49618-d605-430c-ad2e-1726671264ff; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=9fdd3182-155c-4219-b08c-2e1327efc2ce; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=9fdd3182-155c-4219-b08c-2e1327efc2ce; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=9a1b4941-cf6e-4d9a-8790-d450fea30731\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 34\n",
      "DEBUG:langsmith.client:Sending compressed multipart request with context: trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=9a1b4941-cf6e-4d9a-8790-d450fea30731; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=cbf49618-d605-430c-ad2e-1726671264ff; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=e6411e14-7fb0-473c-9199-068a8a9a768b; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=e6411e14-7fb0-473c-9199-068a8a9a768b; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=b439446b-94ce-4d19-bff7-2da4bc63245c; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=169da0d5-4687-462c-af07-049785f696eb; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=39da245f-b984-46af-879b-cb654004041d; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=39da245f-b984-46af-879b-cb654004041d; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=169da0d5-4687-462c-af07-049785f696eb; trace=2abb8cdf-515a-49da-94c6-da2572b892a5,id=2abb8cdf-515a-49da-94c6-da2572b892a5\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 34\n",
      "DEBUG:langsmith.client:Sending compressed multipart request with context: trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=565552e4-7983-49b3-9c37-7eb9fd91cc53; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=0e57acf4-4854-48a8-a1e9-94ae994f077b; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=b7686753-d9ba-49d5-bf96-b0e01b857f4b; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=b7686753-d9ba-49d5-bf96-b0e01b857f4b; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=0e57acf4-4854-48a8-a1e9-94ae994f077b; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=565552e4-7983-49b3-9c37-7eb9fd91cc53; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=41a7fe84-2c92-4c3d-b172-8ef7c811e8b1; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=63a22ac0-83cf-40d1-901e-16de83702568; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=11d57452-3778-4ac0-8332-1bbe61942e96; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=11d57452-3778-4ac0-8332-1bbe61942e96; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=2a80e7cd-977f-40b0-8ac2-40447a20da7b\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 34\n",
      "DEBUG:langsmith.client:Sending compressed multipart request with context: trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=2a80e7cd-977f-40b0-8ac2-40447a20da7b; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=63a22ac0-83cf-40d1-901e-16de83702568; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=37fefce5-4801-41cb-b537-986d32fd03d5; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=37fefce5-4801-41cb-b537-986d32fd03d5; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=41a7fe84-2c92-4c3d-b172-8ef7c811e8b1; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=1384f2de-fb9b-4bef-9202-f90f92215773; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=5e50220f-f86d-4440-acd6-d037349dd103; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=5e50220f-f86d-4440-acd6-d037349dd103; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=1384f2de-fb9b-4bef-9202-f90f92215773; trace=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7,id=ab2dd9c8-f9a1-4f8a-9ce9-e22067386eb7\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 34\n",
      "DEBUG:langsmith.client:Sending compressed multipart request with context: trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=f74c8f76-ed6c-421e-a7d1-f454ea506fa7; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=64761bc3-e467-40b3-8f7e-9dda63fb799a; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=1770c5b1-fa1d-4f3b-b865-19427ab51f78; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=adc7e972-983e-4031-9a21-0595e704ce0b; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=adc7e972-983e-4031-9a21-0595e704ce0b; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=1770c5b1-fa1d-4f3b-b865-19427ab51f78; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=64761bc3-e467-40b3-8f7e-9dda63fb799a; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=c0bd2b86-5bbd-429d-8ae2-758498b230d7; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=51ade19d-93df-475c-addd-5db58e4f2624; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=c436d8e1-33fa-4ae0-a1ff-f0b3874c6fa4; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=c436d8e1-33fa-4ae0-a1ff-f0b3874c6fa4; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=2202efb6-2a97-4e92-8f58-7a156d2d1831\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 34\n",
      "DEBUG:langsmith.client:Sending compressed multipart request with context: trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=2202efb6-2a97-4e92-8f58-7a156d2d1831; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=51ade19d-93df-475c-addd-5db58e4f2624; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=85d22608-207b-4e44-b0c7-e40704b438ca; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=85d22608-207b-4e44-b0c7-e40704b438ca; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=c0bd2b86-5bbd-429d-8ae2-758498b230d7; trace=f74c8f76-ed6c-421e-a7d1-f454ea506fa7,id=f74c8f76-ed6c-421e-a7d1-f454ea506fa7\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/1.1\" 202 34\n"
     ]
    }
   ],
   "source": [
    "result = arxiv_search(\"Quantum Machine Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be0cb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wikipedia\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "wikipedia_tool = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(load_all_available_meta=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa930a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#youtube\n",
    "from langchain_community.tools import YouTubeSearchTool\n",
    "youtube_tool = YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b957f552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): youtube.com:443\n",
      "DEBUG:urllib3.connectionpool:https://youtube.com:443 \"GET /results?search_query=CampusX HTTP/1.1\" 301 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): www.youtube.com:443\n",
      "DEBUG:urllib3.connectionpool:https://www.youtube.com:443 \"GET /results?search_query=CampusX HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/shorts/y9XnfQdOMRQ', 'https://www.youtube.com/shorts/dMBVuRYzAKs']\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_tool.run(\"CampusX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41788055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.tools import Tool,tool\n",
    "python_repl = PythonREPL()\n",
    "# You can create the tool to pass to an agent\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class PythonREPLInput(BaseModel):\n",
    "    code: str\n",
    "\n",
    "repl_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=\"A Python shell. Input should be Python code as a string.\",\n",
    "    args_schema=PythonREPLInput,\n",
    "    func=lambda code: python_repl.run(code)  # map `code` -> REPL\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec1daf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "#from langgraph.store.sqlite import SqliteStore\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.config import get_store\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Optional\n",
    "\n",
    "store = InMemoryStore() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "325ae933",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_user_info(config: RunnableConfig) -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    store = get_store()\n",
    "    user_id = config['configurable'].get(\"user_id\")\n",
    "    user_info = store.get((\"users\",),user_id)\n",
    "    return str(user_info.value) if user_info else \"Unknown user\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b6f36c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "    \n",
    "\n",
    "@tool \n",
    "def save_user_info(user_info: Dict[str, Any], config: RunnableConfig) -> str:\n",
    "    \"\"\"\n",
    "    Save arbitrary user info as key-value pairs.\n",
    "    Always pass `user_info` as a JSON object (not a string).\n",
    "    Example: {\"name\": \"John\", \"age\": 30}\n",
    "    \"\"\"\n",
    "    store = get_store()\n",
    "    user_id = config['configurable'].get(\"user_id\")\n",
    "    store.put((\"users\",), user_id, user_info)\n",
    "    return \"Successfully saved user info \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "243a1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools\n",
    "tools = [get_user_info,save_user_info,add_human_in_the_loop(repl_tool),arxiv_search,wikipedia_tool,youtube_tool,read_tool, add_human_in_the_loop(write_tool), list_tool,web_search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a39f62f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look up user info.\n",
      "Save arbitrary user info as key-value pairs.\n",
      "Always pass `user_info` as a JSON object (not a string).\n",
      "Example: {\"name\": \"John\", \"age\": 30}\n",
      "A Python shell. Input should be Python code as a string.\n",
      "Searches arXiv for papers matching the query.\n",
      "- query: keywords, authors or title\n",
      "- max_results: number of papers to return\n",
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional\n",
      "Read file from disk\n",
      "Write file to disk\n",
      "List files and directories in a specified folder\n",
      "A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.\n"
     ]
    }
   ],
   "source": [
    "for t in tools:\n",
    "    print(t.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be4a34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm\n",
    "llm = ChatGoogleGenerativeAI(model = 'gemini-2.5-flash')\n",
    "llm_with_tools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93797cc",
   "metadata": {},
   "source": [
    "GRAPH BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ea6cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem.short_term import SummarizationNode, RunningSummary\n",
    "from langchain_core.messages import AnyMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52228cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages : Annotated[list[BaseMessage],add_messages]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d617a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.utils import trim_messages, count_tokens_approximately\n",
    "from langchain_core.messages import BaseMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17e79e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "CURRENT_TIME_IST = datetime.now().astimezone().strftime(\"%Y-%m-%d %H:%M %Z\")\n",
    "\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are an intelligent reasoning agent that helps users by combining natural conversation \n",
    "with external tools when needed.\n",
    "\n",
    "tools available :  arxiv_search, read_tool, write_tool, list_tool, duck_search, tavily_search, wikipedia_tool,\n",
    "    youtube_search_tool, youtube_transcript_tool, repl_tool, add_event, list_events, read_webpage,\n",
    "    generate_pdf, shopping_search, create_ticket, list_tickets, get_ticket_details,  update_ticket, news_search,\n",
    "\n",
    "\n",
    "Current date/time: {CURRENT_TIME_IST}\n",
    "\n",
    "\n",
    "\n",
    "### Reasoning Framework\n",
    "Follow the ReAct reasoning loop:\n",
    "1. **Thought** — explain what you are thinking or planning.\n",
    "2. **Action** — choose the correct tool to use.\n",
    "3. **Action Input** — provide the exact structured input for the tool.\n",
    "4. **Observation** — read the tool's result and update your reasoning.\n",
    "\n",
    "Repeat this loop until you can confidently respond to the user.\n",
    "\n",
    "### Style & Tone\n",
    "- Be concise but complete.\n",
    "- Use plain language that non-technical users can understand.\n",
    "- If user input is ambiguous, ask clarifying questions before acting.\n",
    "- Never hallucinate tool outputs. If unsure, say so.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa66dd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_node(state: State):\n",
    "\n",
    "\n",
    "    planner_prompt = ChatPromptTemplate.from_messages([\n",
    "        ('system',system_prompt),\n",
    "        MessagesPlaceholder(variable_name='messages')\n",
    "    ])\n",
    "\n",
    "\n",
    "    planner = planner_prompt | llm_with_tools\n",
    "    result = planner.invoke({'messages': state[\"messages\"]})\n",
    "\n",
    "\n",
    "    return ({'messages':result}) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "772b7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(State)\n",
    "checkpointer = InMemorySaver()\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "graph.add_node('planner_node',planner_node)\n",
    "graph.add_node('tools',tool_node)\n",
    "\n",
    "graph.add_edge(START,'planner_node')\n",
    "\n",
    "graph.add_conditional_edges('planner_node',tools_condition)\n",
    "graph.add_edge('tools','planner_node')\n",
    "graph = graph.compile(checkpointer=checkpointer,store=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abe89fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d733a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"write a 4 line poem on bengal tiger save first 2 line in tr.txt save the last 2 line in er.txt\")]\n",
    "}\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"fqo\" ,\"user_id\": \"user_00\"}}\n",
    "# Run the agent\n",
    "chunk =  graph.invoke(\n",
    "    initial_state,\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c6e01d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='write a 4 line poem on bengal tiger save first 2 line in tr.txt save the last 2 line in er.txt', additional_kwargs={}, response_metadata={}, id='6817da89-a88d-42de-8bef-5411892b106f'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'write_file', 'arguments': '{\"file_path\": \"tr.txt\", \"text\": \"Majestic stripes, a fiery gaze,\\\\nThrough Sundarbans, it softly strays.\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--9a1b4941-cf6e-4d9a-8790-d450fea30731-0', tool_calls=[{'name': 'write_file', 'args': {'file_path': 'tr.txt', 'text': 'Majestic stripes, a fiery gaze,\\nThrough Sundarbans, it softly strays.'}, 'id': 'e1c8b64b-9bb4-4911-8ce0-77f375f1a56e', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2125, 'output_tokens': 135, 'total_tokens': 2260, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 94}})],\n",
       " '__interrupt__': [Interrupt(value=[{'action_request': {'action': 'write_file', 'args': {'file_path': 'tr.txt', 'text': 'Majestic stripes, a fiery gaze,\\nThrough Sundarbans, it softly strays.'}}, 'config': {'allow_accept': True, 'allow_edit': True, 'allow_respond': True}, 'description': 'Please review the tool call'}], id='920edfd3be20d9fbac419f7681b225bc')]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ade4e1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tools': {'messages': [ToolMessage(content='File written successfully to er.txt.', name='write_file', id='57320d48-027a-42bd-8f59-1d1829d60e89', tool_call_id='04f52fd8-259b-464c-b6b8-e42d20ae6d43')]}}\n",
      "\n",
      "\n",
      "{'planner_node': {'messages': AIMessage(content=\"Here is a 4-line poem about saving the Bengal tiger, with the first two lines saved in `tr.txt` and the last two lines in `er.txt`:\\n\\n**tr.txt:**\\nMajestic stripes, a fiery gaze,\\nThrough Sundarbans, it softly strays.\\n\\n**er.txt:**\\nA symbol grand, of wild's embrace,\\nMay efforts rise, to save its grace.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--2202efb6-2a97-4e92-8f58-7a156d2d1831-0', usage_metadata={'input_tokens': 2252, 'output_tokens': 90, 'total_tokens': 2342, 'input_token_details': {'cache_read': 0}})}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command\n",
    "user_input = input(\"Do you accept: ?\")\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    Command(resume=[{\"type\": user_input}]),\n",
    "    config\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
